# í˜„ì¬ ëª¨ë“ˆí™” í•˜ê³  ë‚˜ì„œ ìˆ˜ì • ì•ˆí•´ì„œ ì•„ë§ˆ ì œëŒ€ë¡œ ì‘ë™ ì•ˆí• ë“¯

import os
import pandas as pd
import numpy as np
from PIL import Image
from tqdm import tqdm
import json # class_names ë¡œë“œë¥¼ ìœ„í•´ ì¶”ê°€
import torch
from torch.utils.data import Dataset, DataLoader
import torchvision.transforms as transforms
import torch.nn.functional as F
# train.pyì—ì„œ í•„ìš”í•œ í´ë˜ìŠ¤ì™€ í•¨ìˆ˜, CFGë¥¼ ê°€ì ¸ì˜´
from albu_train import CustomTimmModel, CFG as TRAIN_CFG
from utils import *

# Device Setting
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Inference Configuration
CFG_INF = {
    'MODEL_PATH': '/project/ahnailab/jys0207/CP/lexxsh_project_3/hecto/checkpoint/0519/best_model_convnext_base(1214).pth', # í•™ìŠµ í›„ ìƒì„±ëœ ì‹¤ì œ ëª¨ë¸ ê²½ë¡œë¡œ ìˆ˜ì • í•„ìš”
    'ROOT': '/project/ahnailab/jys0207/CP/lexxsh_project_3/hecto/test',
    'SUBMISSION_FILE': '/project/ahnailab/jys0207/CP/lexxsh_project_3/hecto/sample_submission.csv',
    'BATCH_SIZE': 64, # ì¶”ë¡  ì‹œ ë°°ì¹˜ í¬ê¸°
    'TTA_TIMES': 4, # tta ìˆ˜í–‰ íšŸìˆ˜
    # MODEL_NAME, IMG_SIZE ë“±ì€ TRAIN_CFGì—ì„œ ê°€ì ¸ì™€ ì‚¬ìš©
    'MODEL_NAME': TRAIN_CFG['MODEL_NAME'],
    'IMG_SIZE': TRAIN_CFG['IMG_SIZE'],
    'SEED': TRAIN_CFG['SEED'] # ì¼ê´€ì„±ì„ ìœ„í•´ ì‹œë“œ ì„¤ì •
}

# ì´ë¯¸ì§€ ë³€í™˜ ì •ì˜ (val_transformì€ inf.pyì—ì„œë„ ìœ ì‚¬í•˜ê²Œ ì‚¬ìš©)
tta_transform = transforms.Compose([
    transforms.Resize((CFG_INF['IMG_SIZE'], CFG_INF['IMG_SIZE'])),
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(15),
    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),
    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1), shear=10),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

class TTATestCustomImageDataset(Dataset):
    def __init__(self, root_dir, transform, tta_times=4):
        """
        Args:
            root_dir (str): í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ê°€ ìˆëŠ” í´ë” ê²½ë¡œ
            transform (Transform): ë‹¨ì¼ transform (e.g. train_transform)
            tta_times (int): ë™ì¼ ì´ë¯¸ì§€ì— ëª‡ ë²ˆ transformì„ ì ìš©í• ì§€
        """
        self.root_dir = root_dir
        self.transform = transform
        self.tta_times = tta_times
        self.samples = []

        if not os.path.exists(root_dir) or not os.path.isdir(root_dir):
            print(f"Warning: Test directory {root_dir} not found or is not a directory.")
            return
        
        for fname in sorted(os.listdir(root_dir)):
            if fname.lower().endswith(('.jpg', '.jpeg', '.png')):
                img_path = os.path.join(root_dir, fname)
                self.samples.append((img_path,))

    def __len__(self):
        return len(self.samples)

    def __getitem__(self, idx):
        img_path = self.samples[idx][0]
        try:
            image = Image.open(img_path).convert('RGB')
        except FileNotFoundError:
            return [torch.zeros((3, CFG_INF['IMG_SIZE'], CFG_INF['IMG_SIZE'])) for _ in range(self.tta_times)]

        images = [self.transform(image) for _ in range(self.tta_times)]
        return images  # (tta_times, C, H, W)


def inference_main():
    print("Using device:", device)
    print(f"Inference CFG: {CFG_INF}")
    seed_everything(CFG_INF['SEED'])

    # class_names ë¡œë“œ
    try:
        with open('class_names.json', 'r') as f:
            class_names = json.load(f)
    except FileNotFoundError:
        print("Error: class_names.json not found. Please run train.py first to generate it.")
        return
    num_classes = len(class_names)
    print(f"Loaded class_names: {class_names} (Total: {num_classes})")


    # í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ë° DataLoader
    test_root = CFG_INF['ROOT'] # í…ŒìŠ¤íŠ¸ ë°ì´í„° ê²½ë¡œ
    test_dataset = TTATestCustomImageDataset(test_root, transform=tta_transform, tta_times=CFG_INF['TTA_TIMES']) # train.pyì˜ val_transformê³¼ ë™ì¼í•œ ê²ƒì„ ì‚¬ìš©
    
    if not test_dataset.samples:
        print(f"No images found in {test_root} for inference. Skipping submission file generation.")
        return
    
    test_loader = DataLoader(test_dataset, batch_size=CFG_INF['BATCH_SIZE'], shuffle=False, num_workers=2, pin_memory=True)

    # ëª¨ë¸ ë¡œë“œ
    model = CustomTimmModel(model_name=CFG_INF['MODEL_NAME'], num_classes_to_predict=num_classes).to(device)
    
    model_path = CFG_INF['MODEL_PATH']
    if not os.path.exists(model_path):
        print(f"Error: Model file {model_path} not found. Please check the path in CFG_INF['MODEL_PATH'].")
        print("You might need to run train.py first or update the path to the desired .pth file.")
        return
        
    try:
        model.load_state_dict(torch.load(model_path, map_location=device))
        print(f"Loaded model from {model_path}")
    except Exception as e:
        print(f"Error loading model state_dict from {model_path}: {e}")
        print("Ensure the model architecture in train.py (CustomTimmModel) matches the saved model.")
        return

    model.eval()
    results = []
    with torch.no_grad():
        for tta_images in tqdm(test_loader, desc="Inference"):
            # tta_images: list of batch, each item is list of T tensors
            # Shape: [T, B, C, H, W]  if collate_fnë¥¼ ì•ˆ ì¼ë‹¤ë©´, ê¸°ë³¸ì€ list[Tensor]

            # ë°°ì¹˜ ë‚´ ê° ìƒ˜í”Œë³„ TTA ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸ë¡œ êµ¬ì„±ëœ ê²½ìš° ì²˜ë¦¬
            tta_probs = 0
            for sample_images in tta_images:  # sample_images: List[Tensor], len == tta_times
                images = sample_images.to(device)  # (1, C, H, W)
                output = model(images)
                tta_probs += (F.softmax(output, dim=1) / CFG_INF['TTA_TIMES'])

            # í•˜ë‚˜ì˜ ë°°ì¹˜ë¡œ í•©ì¹˜ê¸°
            results.extend(tta_probs.detach().cpu().numpy())

    pred_df = pd.DataFrame(results, columns=class_names)
    pred_df.to_csv("./tmp.csv")

    # Submission íŒŒì¼ ìƒì„±
    submission_file_path = CFG_INF['SUBMISSION_FILE'] # ìƒ˜í”Œ ì œì¶œ íŒŒì¼ ê²½ë¡œ
    try:
        submission_df = pd.read_csv(submission_file_path, encoding='utf-8-sig')
    except FileNotFoundError:
        print(f"Error: Sample submission file {submission_file_path} not found.")
        return

    class_columns_in_submission = submission_df.columns[1:]
    try:
        submission_df[class_columns_in_submission] = pred_df[class_columns_in_submission].values
    except KeyError as e:
        print(f"KeyError during submission assignment: {e}")
        print(f"Make sure class_names.json and sample_submission.csv columns align with model output.")
        return
    except ValueError as e:
        print(f"ValueError during submission assignment: {e}")
        return


    # ì¶œë ¥ íŒŒì¼ëª…ì— ëª¨ë¸ ì´ë¦„ê³¼ (ë‹¨ì¼ í´ë“œ ì‹¤í–‰ ì‹œ) í´ë“œ ë²ˆí˜¸ ë˜ëŠ” 'best_overall' í¬í•¨
    base_output_filename = f'submission_{CFG_INF["MODEL_NAME"]}'
    # TRAIN_CFGì—ì„œ RUN_SINGLE_FOLDì™€ TARGET_FOLDë¥¼ ì°¸ì¡°í•˜ì—¬ íŒŒì¼ëª… ê²°ì •
    if TRAIN_CFG.get('RUN_SINGLE_FOLD', False) and TRAIN_CFG.get('TARGET_FOLD') is not None and CFG_INF['MODEL_PATH'].endswith(f"_fold{TRAIN_CFG['TARGET_FOLD']}.pth"):
         base_output_filename += f'_fold{TRAIN_CFG["TARGET_FOLD"]}'
    elif "_fold" in CFG_INF['MODEL_PATH']: # ê²½ë¡œì— fold ì •ë³´ê°€ ìˆë‹¤ë©´ ì‚¬ìš©
        try:
            fold_num_from_path = CFG_INF['MODEL_PATH'].split('_fold')[1].split('.pth')[0]
            base_output_filename += f'_fold{fold_num_from_path}'
        except: # ê²½ë¡œ íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì¼ë°˜ ì´ë¦„ ì‚¬ìš©
            if "overall" not in CFG_INF['MODEL_PATH'].lower(): # overallì´ ì•„ë‹ˆë©´ ê²½ë¡œëª… ì¼ë¶€ ì‚¬ìš© ì‹œë„
                 path_part = os.path.basename(CFG_INF['MODEL_PATH']).replace('.pth','').replace('best_model_','')
                 base_output_filename = f'submission_{path_part}'


    output_submission_filename = f'{base_output_filename}.csv'

    submission_df.to_csv(output_submission_filename, index=False, encoding='utf-8-sig')
    print(f"ğŸ‰ Submission file created successfully: {output_submission_filename}")

if __name__ == '__main__':
    inference_main()