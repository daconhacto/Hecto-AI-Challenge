{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from augmentations import *\n",
    "from dataset import *\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.transforms import v2\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter Setting\n",
    "CFG = {\n",
    "    \"ROOT\": '../train_final', # 학습 데이터 경로\n",
    "    \"WORK_DIR\": './final_kold/final_fold4',\n",
    "    # retraining 설정\n",
    "    \"START_FROM\": None, # 만약 None이 아닌 .pth파일 경로 입력하면 해당 checkpoint를 load해서 시작\n",
    "    \"GROUP_PATH\": None, # 만약 None이 아닌 group.json의 경로르 입력하면 해당 class들만 활용하여 train을 진행함\n",
    "    \n",
    "    # wrong example을 뽑을 threshold 조건. threshold 이하인 confidence를 가지는 케이스를 저장.\n",
    "    \"WRONG_THRESHOLD\": 0.7,\n",
    "    \"GROUP_JSON_START_EPOCH\": 5, # work_dir에 해당 에폭부터의 wrong_examples를 통합한 json파일을 저장하게됩니다.\n",
    "\n",
    "    # 해당 augmentation들은 선택된 것들 중 랜덤하게 '1개'만 적용이 됩니다(배치마다 랜덤하게 1개 선택)\n",
    "    \"ALL_AUGMENTATIONS\": [\"CUTMIX\", \"MIXUP\", \"MOSAIC\", \"CUTOUT\", \"SALIENCYMIX\"], # 여기에 정의되어 있는 것 중 True만 실제 적용. \n",
    "    \"NONE_AUGMENTATION_LIST\": [],\n",
    "    \"CUTMIX\": {\n",
    "        'enable': False,\n",
    "        'params':{'alpha':1.0} # alpha값 float로 정의 안하면 오류남\n",
    "    },\n",
    "    \"SALIENCYMIX\": {\n",
    "        'enable': False,\n",
    "        'params':{'alpha':1.0, 'num_candidates':9}\n",
    "    },\n",
    "    \"MIXUP\": {\n",
    "        'enable': True,\n",
    "        'params':{'alpha':1.0} # alpha값 float로 정의 안하면 오류남\n",
    "    },\n",
    "    \"MOSAIC\": {\n",
    "        'enable': False,\n",
    "        'params':{\n",
    "            'p': 1.0,\n",
    "            'grid_size': 2,\n",
    "            'use_saliency': False\n",
    "        }\n",
    "    },\n",
    "    \"CUTOUT\": {\n",
    "        'enable': False,\n",
    "        'params':{\n",
    "            'mask_size': 32\n",
    "        }\n",
    "    },\n",
    "\n",
    "    # 기타 설정값들\n",
    "    'IMG_SIZE': 600, # Number or Tuple(Height, Width)\n",
    "    'BATCH_SIZE': 32, # 학습 시 배치 크기\n",
    "    'EPOCHS': 35,\n",
    "    'SEED' : 42,\n",
    "    'MODEL_NAME': 'convnext_large_mlp.clip_laion2b_augreg_ft_in1k_384',\n",
    "    'N_FOLDS': 5,\n",
    "    'EARLY_STOPPING_PATIENCE': 5,\n",
    "    'RUN_SINGLE_FOLD': True,  # True로 설정 시 특정 폴드만 실행\n",
    "    'TARGET_FOLD': 4,          # RUN_SINGLE_FOLD가 True일 때 실행할 폴드 번호 (1-based)\n",
    "    \n",
    "\n",
    "    # 새롭게 추가된 logging파트. class의 경우 무조건 풀경로로 적어야합니다. nn.CrossEntropyLoss 처럼 적으면 오류남\n",
    "    'LOSS': {\n",
    "        'class': 'torch.nn.CrossEntropyLoss',\n",
    "        'params': {}   \n",
    "    },\n",
    "    'OPTIMIZER': {\n",
    "        'class': 'torch.optim.AdamW',\n",
    "        'params': {\n",
    "            'lr': 2e-05,\n",
    "            'weight_decay': 0.01\n",
    "        }\n",
    "    },\n",
    "    'SCHEDULER': {\n",
    "        'class': 'torch.optim.lr_scheduler.CosineAnnealingLR',\n",
    "        'params': {\n",
    "            'T_max': 35,\n",
    "            'eta_min': 2e-08\n",
    "        }\n",
    "    },\n",
    "}\n",
    "\n",
    "CFG['IMG_SIZE'] = CFG['IMG_SIZE'] if isinstance(CFG['IMG_SIZE'], tuple) else (CFG['IMG_SIZE'], CFG['IMG_SIZE'])\n",
    "# --- Albumentations 기반 이미지 변환 정의 ---\n",
    "train_transform = A.Compose([\n",
    "    CustomCropTransformConsiderRatio(p=0.5, consider_ratio=True),\n",
    "    A.Resize(CFG['IMG_SIZE'][0], CFG['IMG_SIZE'][1]),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.Rotate(limit=15, p=0.5),\n",
    "    A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1, p=0.5),\n",
    "    A.Affine(translate_percent=(0.1, 0.1), scale=(0.9, 1.1), shear=10, rotate=0, p=0.5),\n",
    "    A.Normalize(mean=[0.0, 0.0, 0.0], std=[1.0, 1.0, 1.0]),\n",
    "    ToTensorV2()\n",
    "], seed=CFG['SEED'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_root = CFG['ROOT']\n",
    "initial_dataset = InitialCustomImageDataset(train_root)\n",
    "if not initial_dataset.samples:\n",
    "    raise ValueError(f\"No images found in {train_root}. Please check the path and data structure.\")\n",
    "print(f\"총 학습 이미지 수 (K-Fold 대상): {len(initial_dataset.samples)}\")\n",
    "\n",
    "all_samples = initial_dataset.samples\n",
    "targets = [s[1] for s in all_samples]\n",
    "class_names = initial_dataset.classes\n",
    "num_classes = len(class_names)\n",
    "print(f\"클래스: {class_names} (총 {num_classes}개)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = FoldSpecificDataset(all_samples, image_size = CFG['IMG_SIZE'], transform=train_transform, is_train=False)\n",
    "train_loader = DataLoader(train_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mix_augmentations = RandomMixAugmentation(CFG, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_transformed_vs_original(dataloader, num_samples=10, device='cpu'):\n",
    "    \"\"\"\n",
    "    무작위 배치 하나에서 num_samples만큼의 이미지에 대해\n",
    "    원본 이미지와 transform된 이미지를 나란히 시각화.\n",
    "\n",
    "    Args:\n",
    "        dataloader: PyTorch DataLoader\n",
    "        num_samples: 시각화할 이미지 수\n",
    "        device: 'cuda' 또는 'cpu'\n",
    "    \"\"\"\n",
    "    # dataloader에서 배치 하나만 추출\n",
    "    for images, labels, img_paths in dataloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        print(labels)\n",
    "        num_samples = min(num_samples, images.size(0))\n",
    "        \n",
    "        images, labels = all_mix_augmentations.forward(images, labels)\n",
    "\n",
    "        fig, axs = plt.subplots(num_samples, 2, figsize=(10, 5 * num_samples))\n",
    "\n",
    "        if num_samples == 1:\n",
    "            axs = [axs]\n",
    "\n",
    "        for i in range(num_samples):\n",
    "            # transform된 이미지 (Tensor → numpy)\n",
    "            print(img_paths[i])\n",
    "            transformed_img = images[i].cpu()\n",
    "            transformed_np = transformed_img.permute(1, 2, 0).numpy()\n",
    "\n",
    "            # 원본 이미지 (img_path에서 로드)\n",
    "            original_img = Image.open(img_paths[i]).convert('RGB')\n",
    "\n",
    "            axs[i][0].imshow(original_img)\n",
    "            # axs[i][0].set_title(f\"Original: {img_paths[i].split('/')[-1]}\")\n",
    "            axs[i][0].set_title(f\"Original\")\n",
    "            axs[i][0].axis('off')\n",
    "\n",
    "            axs[i][1].imshow(transformed_np)\n",
    "            axs[i][1].set_title(\"Transformed\")\n",
    "            axs[i][1].axis('off')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_transformed_vs_original(train_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
